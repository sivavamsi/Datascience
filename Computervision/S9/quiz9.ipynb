{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "############ DATA & TRANSFORMS\n",
    "\n",
    "from data import get_data\n",
    "from device import get_device\n",
    "\n",
    "device = get_device(force_cpu=False)\n",
    "\n",
    "\n",
    "horizontal_flip_prob = 0.2\n",
    "vertical_flip_prob = 0.0\n",
    "gaussian_blur_prob = 0.0\n",
    "rotate_degree = 20\n",
    "cutout = 0.3\n",
    "#\n",
    "transform_args = {}\n",
    "\n",
    "\n",
    "transform_args['horizontal_flip_prob'] =  0.2\n",
    "transform_args['vertical_flip_prob'] = 0.0\n",
    "transform_args['gaussian_blur_prob'] = 0.0\n",
    "transform_args['rotate_degree'] = 20\n",
    "transform_args['cutout'] = 0.3\n",
    "transform_args['cutout_height'] = 16\n",
    "transform_args['cutout_width'] = 16\n",
    "\n",
    "\n",
    "train_loader, test_loader = get_data(device,transform_args,batch_size=64 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             448\n",
      "              ReLU-2           [-1, 16, 32, 32]               0\n",
      "       BatchNorm2d-3           [-1, 16, 32, 32]              32\n",
      "           Dropout-4           [-1, 16, 32, 32]               0\n",
      "            Conv2d-5           [-1, 16, 32, 32]           2,320\n",
      "              ReLU-6           [-1, 16, 32, 32]               0\n",
      "       BatchNorm2d-7           [-1, 16, 32, 32]              32\n",
      "           Dropout-8           [-1, 16, 32, 32]               0\n",
      "         MaxPool2d-9           [-1, 16, 16, 16]               0\n",
      "           Conv2d-10           [-1, 32, 16, 16]           4,640\n",
      "             ReLU-11           [-1, 32, 16, 16]               0\n",
      "      BatchNorm2d-12           [-1, 32, 16, 16]              64\n",
      "          Dropout-13           [-1, 32, 16, 16]               0\n",
      "           Conv2d-14           [-1, 32, 16, 16]           9,248\n",
      "             ReLU-15           [-1, 32, 16, 16]               0\n",
      "      BatchNorm2d-16           [-1, 32, 16, 16]              64\n",
      "          Dropout-17           [-1, 32, 16, 16]               0\n",
      "           Conv2d-18           [-1, 32, 16, 16]           9,248\n",
      "             ReLU-19           [-1, 32, 16, 16]               0\n",
      "      BatchNorm2d-20           [-1, 32, 16, 16]              64\n",
      "          Dropout-21           [-1, 32, 16, 16]               0\n",
      "        MaxPool2d-22             [-1, 32, 8, 8]               0\n",
      "           Conv2d-23             [-1, 64, 8, 8]          18,496\n",
      "             ReLU-24             [-1, 64, 8, 8]               0\n",
      "      BatchNorm2d-25             [-1, 64, 8, 8]             128\n",
      "          Dropout-26             [-1, 64, 8, 8]               0\n",
      "           Conv2d-27             [-1, 64, 8, 8]          36,928\n",
      "             ReLU-28             [-1, 64, 8, 8]               0\n",
      "      BatchNorm2d-29             [-1, 64, 8, 8]             128\n",
      "          Dropout-30             [-1, 64, 8, 8]               0\n",
      "           Conv2d-31             [-1, 64, 8, 8]          36,928\n",
      "             ReLU-32             [-1, 64, 8, 8]               0\n",
      "      BatchNorm2d-33             [-1, 64, 8, 8]             128\n",
      "          Dropout-34             [-1, 64, 8, 8]               0\n",
      "AdaptiveAvgPool2d-35             [-1, 64, 1, 1]               0\n",
      "           Linear-36                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 119,546\n",
      "Trainable params: 119,546\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.17\n",
      "Params size (MB): 0.46\n",
      "Estimated Total Size (MB): 2.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "##################### MODEL\n",
    "\n",
    "from QuizDNNpy import NetCifar\n",
    "from torchsummary import summary\n",
    "model = NetCifar().to(device)\n",
    "\n",
    "summary(model, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:\n",
      "(TRAIN) batch_number:  100 Loss : 1.758 Acc : 0.27859\n",
      "(TRAIN) batch_number:  200 Loss : 1.636 Acc : 0.32539\n",
      "(TRAIN) batch_number:  300 Loss : 1.744 Acc : 0.35823\n",
      "(TRAIN) batch_number:  400 Loss : 1.471 Acc : 0.38559\n",
      "(TRAIN) batch_number:  500 Loss : 1.224 Acc : 0.40637\n",
      "(TRAIN) batch_number:  600 Loss : 1.206 Acc : 0.42385\n",
      "(TRAIN) batch_number:  700 Loss : 1.433 Acc : 0.43817\n",
      "(TEST) Correct_classified :  5687  of 10000\n",
      "(TEST) Loss : 1.194 Acc : 0.5687\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 2:\n",
      "(TRAIN) batch_number:  100 Loss : 1.198 Acc : 0.55531\n",
      "(TRAIN) batch_number:  200 Loss : 1.285 Acc : 0.56211\n",
      "(TRAIN) batch_number:  300 Loss : 1.303 Acc : 0.56922\n",
      "(TRAIN) batch_number:  400 Loss : 1.079 Acc : 0.57551\n",
      "(TRAIN) batch_number:  500 Loss : 1.024 Acc : 0.579\n",
      "(TRAIN) batch_number:  600 Loss : 1.124 Acc : 0.58552\n",
      "(TRAIN) batch_number:  700 Loss : 1.019 Acc : 0.59016\n",
      "(TEST) Correct_classified :  6606  of 10000\n",
      "(TEST) Loss : 0.9735 Acc : 0.6606\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 3:\n",
      "(TRAIN) batch_number:  100 Loss : 1.311 Acc : 0.64453\n",
      "(TRAIN) batch_number:  200 Loss : 1.235 Acc : 0.63961\n",
      "(TRAIN) batch_number:  300 Loss : 0.9623 Acc : 0.63745\n",
      "(TRAIN) batch_number:  400 Loss : 0.8089 Acc : 0.64242\n",
      "(TRAIN) batch_number:  500 Loss : 0.775 Acc : 0.64691\n",
      "(TRAIN) batch_number:  600 Loss : 0.9496 Acc : 0.65081\n",
      "(TRAIN) batch_number:  700 Loss : 0.7612 Acc : 0.65411\n",
      "(TEST) Correct_classified :  7076  of 10000\n",
      "(TEST) Loss : 0.8343 Acc : 0.7076\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 4:\n",
      "(TRAIN) batch_number:  100 Loss : 0.924 Acc : 0.68953\n",
      "(TRAIN) batch_number:  200 Loss : 0.9089 Acc : 0.69227\n",
      "(TRAIN) batch_number:  300 Loss : 0.91 Acc : 0.69182\n",
      "(TRAIN) batch_number:  400 Loss : 0.8444 Acc : 0.69309\n",
      "(TRAIN) batch_number:  500 Loss : 0.8605 Acc : 0.69147\n",
      "(TRAIN) batch_number:  600 Loss : 0.8482 Acc : 0.69268\n",
      "(TRAIN) batch_number:  700 Loss : 0.7422 Acc : 0.69491\n",
      "(TEST) Correct_classified :  7164  of 10000\n",
      "(TEST) Loss : 0.8046 Acc : 0.7164\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 5:\n",
      "(TRAIN) batch_number:  100 Loss : 0.7666 Acc : 0.71469\n",
      "(TRAIN) batch_number:  200 Loss : 0.7007 Acc : 0.71969\n",
      "(TRAIN) batch_number:  300 Loss : 0.7822 Acc : 0.71688\n",
      "(TRAIN) batch_number:  400 Loss : 0.9398 Acc : 0.71535\n",
      "(TRAIN) batch_number:  500 Loss : 0.7209 Acc : 0.71484\n",
      "(TRAIN) batch_number:  600 Loss : 0.8142 Acc : 0.71607\n",
      "(TRAIN) batch_number:  700 Loss : 0.657 Acc : 0.71533\n",
      "(TEST) Correct_classified :  7479  of 10000\n",
      "(TEST) Loss : 0.7389 Acc : 0.7479\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 6:\n",
      "(TRAIN) batch_number:  100 Loss : 0.7963 Acc : 0.75016\n",
      "(TRAIN) batch_number:  200 Loss : 0.3584 Acc : 0.75328\n",
      "(TRAIN) batch_number:  300 Loss : 0.5221 Acc : 0.7601\n",
      "(TRAIN) batch_number:  400 Loss : 0.6396 Acc : 0.75934\n",
      "(TRAIN) batch_number:  500 Loss : 0.8318 Acc : 0.75987\n",
      "(TRAIN) batch_number:  600 Loss : 0.6957 Acc : 0.76148\n",
      "(TRAIN) batch_number:  700 Loss : 0.6605 Acc : 0.76208\n",
      "(TEST) Correct_classified :  7904  of 10000\n",
      "(TEST) Loss : 0.6127 Acc : 0.7904\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 7:\n",
      "(TRAIN) batch_number:  100 Loss : 0.8733 Acc : 0.75609\n",
      "(TRAIN) batch_number:  200 Loss : 0.5618 Acc : 0.76539\n",
      "(TRAIN) batch_number:  300 Loss : 0.5351 Acc : 0.76693\n",
      "(TRAIN) batch_number:  400 Loss : 0.7883 Acc : 0.76641\n",
      "(TRAIN) batch_number:  500 Loss : 0.8359 Acc : 0.76725\n",
      "(TRAIN) batch_number:  600 Loss : 0.536 Acc : 0.76826\n",
      "(TRAIN) batch_number:  700 Loss : 0.5956 Acc : 0.76819\n",
      "(TEST) Correct_classified :  7953  of 10000\n",
      "(TEST) Loss : 0.6015 Acc : 0.7953\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 8:\n",
      "(TRAIN) batch_number:  100 Loss : 0.5964 Acc : 0.77687\n",
      "(TRAIN) batch_number:  200 Loss : 0.9074 Acc : 0.77711\n",
      "(TRAIN) batch_number:  300 Loss : 0.6246 Acc : 0.77786\n",
      "(TRAIN) batch_number:  400 Loss : 0.4572 Acc : 0.77676\n",
      "(TRAIN) batch_number:  500 Loss : 0.5476 Acc : 0.77747\n",
      "(TRAIN) batch_number:  600 Loss : 0.6748 Acc : 0.77552\n",
      "(TRAIN) batch_number:  700 Loss :  0.5 Acc : 0.77596\n",
      "(TEST) Correct_classified :  7968  of 10000\n",
      "(TEST) Loss : 0.5959 Acc : 0.7968\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 9:\n",
      "(TRAIN) batch_number:  100 Loss : 0.5872 Acc : 0.78281\n",
      "(TRAIN) batch_number:  200 Loss : 0.6984 Acc : 0.78539\n",
      "(TRAIN) batch_number:  300 Loss : 0.5825 Acc : 0.7824\n",
      "(TRAIN) batch_number:  400 Loss : 0.8715 Acc : 0.78094\n",
      "(TRAIN) batch_number:  500 Loss : 0.7457 Acc : 0.77775\n",
      "(TRAIN) batch_number:  600 Loss : 0.4869 Acc : 0.77805\n",
      "(TRAIN) batch_number:  700 Loss : 0.6098 Acc : 0.77772\n",
      "(TEST) Correct_classified :  8004  of 10000\n",
      "(TEST) Loss : 0.588 Acc : 0.8004\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 10:\n",
      "(TRAIN) batch_number:  100 Loss : 0.6926 Acc : 0.7775\n",
      "(TRAIN) batch_number:  200 Loss : 0.6809 Acc : 0.77797\n",
      "(TRAIN) batch_number:  300 Loss : 0.5312 Acc : 0.77828\n",
      "(TRAIN) batch_number:  400 Loss : 0.7395 Acc : 0.78039\n",
      "(TRAIN) batch_number:  500 Loss : 0.7461 Acc : 0.78263\n",
      "(TRAIN) batch_number:  600 Loss : 0.6276 Acc : 0.78203\n",
      "(TRAIN) batch_number:  700 Loss : 0.54 Acc : 0.78205\n",
      "(TEST) Correct_classified :  8076  of 10000\n",
      "(TEST) Loss : 0.5688 Acc : 0.8076\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 11:\n",
      "(TRAIN) batch_number:  100 Loss : 0.6635 Acc : 0.78578\n",
      "(TRAIN) batch_number:  200 Loss : 0.7331 Acc : 0.79297\n",
      "(TRAIN) batch_number:  300 Loss : 0.6689 Acc : 0.79042\n",
      "(TRAIN) batch_number:  400 Loss : 0.7982 Acc : 0.7898\n",
      "(TRAIN) batch_number:  500 Loss : 0.619 Acc : 0.79012\n",
      "(TRAIN) batch_number:  600 Loss : 0.634 Acc : 0.78932\n",
      "(TRAIN) batch_number:  700 Loss : 0.5224 Acc : 0.78853\n",
      "(TEST) Correct_classified :  8097  of 10000\n",
      "(TEST) Loss : 0.5626 Acc : 0.8097\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 12:\n",
      "(TRAIN) batch_number:  100 Loss : 0.5745 Acc : 0.78875\n",
      "(TRAIN) batch_number:  200 Loss : 0.6228 Acc : 0.79266\n",
      "(TRAIN) batch_number:  300 Loss : 0.4718 Acc : 0.79427\n",
      "(TRAIN) batch_number:  400 Loss : 0.4358 Acc : 0.79484\n",
      "(TRAIN) batch_number:  500 Loss : 0.6795 Acc : 0.79416\n",
      "(TRAIN) batch_number:  600 Loss : 0.3817 Acc : 0.7937\n",
      "(TRAIN) batch_number:  700 Loss : 0.5623 Acc : 0.79342\n",
      "(TEST) Correct_classified :  8074  of 10000\n",
      "(TEST) Loss : 0.5665 Acc : 0.8074\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 13:\n",
      "(TRAIN) batch_number:  100 Loss : 0.6187 Acc : 0.78812\n",
      "(TRAIN) batch_number:  200 Loss : 0.5074 Acc : 0.79031\n",
      "(TRAIN) batch_number:  300 Loss : 0.6786 Acc : 0.78964\n",
      "(TRAIN) batch_number:  400 Loss : 0.717 Acc : 0.79082\n",
      "(TRAIN) batch_number:  500 Loss : 0.5544 Acc : 0.79356\n",
      "(TRAIN) batch_number:  600 Loss : 0.6561 Acc : 0.79367\n",
      "(TRAIN) batch_number:  700 Loss : 0.5941 Acc : 0.79415\n",
      "(TEST) Correct_classified :  8095  of 10000\n",
      "(TEST) Loss : 0.564 Acc : 0.8095\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 14:\n",
      "(TRAIN) batch_number:  100 Loss : 0.6574 Acc : 0.78719\n",
      "(TRAIN) batch_number:  200 Loss : 0.5208 Acc : 0.79445\n",
      "(TRAIN) batch_number:  300 Loss : 0.5786 Acc : 0.79552\n",
      "(TRAIN) batch_number:  400 Loss : 0.8301 Acc : 0.79426\n",
      "(TRAIN) batch_number:  500 Loss : 0.9282 Acc : 0.79466\n",
      "(TRAIN) batch_number:  600 Loss : 0.6865 Acc : 0.79516\n",
      "(TRAIN) batch_number:  700 Loss : 0.5371 Acc : 0.79563\n",
      "(TEST) Correct_classified :  8100  of 10000\n",
      "(TEST) Loss : 0.5658 Acc : 0.81\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 15:\n",
      "(TRAIN) batch_number:  100 Loss : 0.4841 Acc : 0.79937\n",
      "(TRAIN) batch_number:  200 Loss : 0.6393 Acc : 0.79273\n",
      "(TRAIN) batch_number:  300 Loss : 0.4399 Acc : 0.79229\n",
      "(TRAIN) batch_number:  400 Loss : 0.626 Acc : 0.7934\n",
      "(TRAIN) batch_number:  500 Loss : 0.5587 Acc : 0.79259\n",
      "(TRAIN) batch_number:  600 Loss : 0.582 Acc : 0.79253\n",
      "(TRAIN) batch_number:  700 Loss : 0.5125 Acc : 0.79252\n",
      "(TEST) Correct_classified :  8093  of 10000\n",
      "(TEST) Loss : 0.5619 Acc : 0.8093\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 16:\n",
      "(TRAIN) batch_number:  100 Loss : 0.8625 Acc : 0.79125\n",
      "(TRAIN) batch_number:  200 Loss : 0.6244 Acc : 0.79312\n",
      "(TRAIN) batch_number:  300 Loss : 0.6721 Acc : 0.79286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TRAIN) batch_number:  400 Loss : 0.8247 Acc : 0.7941\n",
      "(TRAIN) batch_number:  500 Loss : 0.4881 Acc : 0.79419\n",
      "(TRAIN) batch_number:  600 Loss : 0.8098 Acc : 0.79609\n",
      "(TRAIN) batch_number:  700 Loss : 0.5021 Acc : 0.79565\n",
      "(TEST) Correct_classified :  8083  of 10000\n",
      "(TEST) Loss : 0.5683 Acc : 0.8083\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 17:\n",
      "(TRAIN) batch_number:  100 Loss : 0.7724 Acc : 0.79609\n",
      "(TRAIN) batch_number:  200 Loss : 0.6578 Acc : 0.79844\n",
      "(TRAIN) batch_number:  300 Loss : 0.5268 Acc : 0.79646\n",
      "(TRAIN) batch_number:  400 Loss : 0.5168 Acc : 0.79688\n",
      "(TRAIN) batch_number:  500 Loss : 0.7177 Acc : 0.79644\n",
      "(TRAIN) batch_number:  600 Loss : 0.5009 Acc : 0.7968\n",
      "(TRAIN) batch_number:  700 Loss : 0.7425 Acc : 0.79734\n",
      "(TEST) Correct_classified :  8114  of 10000\n",
      "(TEST) Loss : 0.5612 Acc : 0.8114\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 18:\n",
      "(TRAIN) batch_number:  100 Loss : 0.6129 Acc : 0.80109\n",
      "(TRAIN) batch_number:  200 Loss : 0.5236 Acc : 0.80266\n",
      "(TRAIN) batch_number:  300 Loss : 0.2874 Acc : 0.80151\n",
      "(TRAIN) batch_number:  400 Loss : 0.5601 Acc : 0.80258\n",
      "(TRAIN) batch_number:  500 Loss : 0.4538 Acc : 0.80141\n",
      "(TRAIN) batch_number:  600 Loss : 0.4035 Acc : 0.79906\n",
      "(TRAIN) batch_number:  700 Loss : 0.6796 Acc : 0.80038\n",
      "(TEST) Correct_classified :  8082  of 10000\n",
      "(TEST) Loss : 0.5669 Acc : 0.8082\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 19:\n",
      "(TRAIN) batch_number:  100 Loss : 0.5978 Acc : 0.79047\n",
      "(TRAIN) batch_number:  200 Loss : 0.5601 Acc : 0.79664\n",
      "(TRAIN) batch_number:  300 Loss : 0.5436 Acc : 0.7987\n",
      "(TRAIN) batch_number:  400 Loss : 0.769 Acc : 0.79996\n",
      "(TRAIN) batch_number:  500 Loss : 0.5206 Acc : 0.79878\n",
      "(TRAIN) batch_number:  600 Loss : 0.59 Acc : 0.79826\n",
      "(TRAIN) batch_number:  700 Loss : 0.6056 Acc : 0.79781\n",
      "(TEST) Correct_classified :  8099  of 10000\n",
      "(TEST) Loss : 0.5603 Acc : 0.8099\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 20:\n",
      "(TRAIN) batch_number:  100 Loss : 0.5464 Acc : 0.79438\n",
      "(TRAIN) batch_number:  200 Loss : 0.5379 Acc : 0.79867\n",
      "(TRAIN) batch_number:  300 Loss : 0.5688 Acc : 0.79703\n",
      "(TRAIN) batch_number:  400 Loss : 0.3215 Acc : 0.79738\n",
      "(TRAIN) batch_number:  500 Loss : 0.6835 Acc : 0.79712\n",
      "(TRAIN) batch_number:  600 Loss : 0.5818 Acc : 0.7975\n",
      "(TRAIN) batch_number:  700 Loss : 0.4981 Acc : 0.79754\n",
      "(TEST) Correct_classified :  8100  of 10000\n",
      "(TEST) Loss : 0.5639 Acc : 0.81\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 21:\n",
      "(TRAIN) batch_number:  100 Loss : 0.6012 Acc : 0.79\n",
      "(TRAIN) batch_number:  200 Loss : 0.5382 Acc : 0.79273\n",
      "(TRAIN) batch_number:  300 Loss : 0.5759 Acc : 0.79771\n",
      "(TRAIN) batch_number:  400 Loss : 0.3882 Acc : 0.79883\n",
      "(TRAIN) batch_number:  500 Loss : 0.4723 Acc : 0.79878\n",
      "(TRAIN) batch_number:  600 Loss : 0.8754 Acc : 0.79846\n",
      "(TRAIN) batch_number:  700 Loss : 0.5284 Acc : 0.79728\n",
      "(TEST) Correct_classified :  8121  of 10000\n",
      "(TEST) Loss : 0.5568 Acc : 0.8121\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 22:\n",
      "(TRAIN) batch_number:  100 Loss : 0.2754 Acc : 0.78984\n",
      "(TRAIN) batch_number:  200 Loss : 0.5835 Acc : 0.7968\n",
      "(TRAIN) batch_number:  300 Loss : 0.6156 Acc : 0.79734\n",
      "(TRAIN) batch_number:  400 Loss : 0.6219 Acc : 0.80023\n",
      "(TRAIN) batch_number:  500 Loss : 0.4631 Acc : 0.79916\n",
      "(TRAIN) batch_number:  600 Loss : 0.666 Acc : 0.79831\n",
      "(TRAIN) batch_number:  700 Loss : 0.549 Acc : 0.79757\n",
      "(TEST) Correct_classified :  8115  of 10000\n",
      "(TEST) Loss : 0.5611 Acc : 0.8115\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 23:\n",
      "(TRAIN) batch_number:  100 Loss : 0.4374 Acc : 0.80547\n",
      "(TRAIN) batch_number:  200 Loss : 0.4869 Acc : 0.80352\n",
      "(TRAIN) batch_number:  300 Loss : 0.7395 Acc : 0.80115\n",
      "(TRAIN) batch_number:  400 Loss : 0.5159 Acc : 0.80371\n",
      "(TRAIN) batch_number:  500 Loss : 0.6022 Acc : 0.80188\n",
      "(TRAIN) batch_number:  600 Loss : 0.7108 Acc : 0.80042\n",
      "(TRAIN) batch_number:  700 Loss : 0.504 Acc : 0.79935\n",
      "(TEST) Correct_classified :  8086  of 10000\n",
      "(TEST) Loss : 0.5647 Acc : 0.8086\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 24:\n",
      "(TRAIN) batch_number:  100 Loss : 0.5165 Acc : 0.80453\n",
      "(TRAIN) batch_number:  200 Loss : 0.5003 Acc : 0.80172\n",
      "(TRAIN) batch_number:  300 Loss : 0.7051 Acc : 0.80177\n",
      "(TRAIN) batch_number:  400 Loss : 0.3844 Acc : 0.80125\n",
      "(TRAIN) batch_number:  500 Loss : 0.57 Acc : 0.80059\n",
      "(TRAIN) batch_number:  600 Loss : 0.5426 Acc : 0.79997\n",
      "(TRAIN) batch_number:  700 Loss : 0.5673 Acc : 0.79991\n",
      "(TEST) Correct_classified :  8105  of 10000\n",
      "(TEST) Loss : 0.5627 Acc : 0.8105\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 25:\n",
      "(TRAIN) batch_number:  100 Loss : 0.6124 Acc : 0.79469\n",
      "(TRAIN) batch_number:  200 Loss : 0.6859 Acc : 0.79992\n",
      "(TRAIN) batch_number:  300 Loss : 0.7543 Acc : 0.79818\n",
      "(TRAIN) batch_number:  400 Loss : 0.3811 Acc : 0.79695\n",
      "(TRAIN) batch_number:  500 Loss : 0.4001 Acc : 0.79788\n",
      "(TRAIN) batch_number:  600 Loss : 0.6695 Acc : 0.79784\n",
      "(TRAIN) batch_number:  700 Loss : 0.4292 Acc : 0.79783\n",
      "(TEST) Correct_classified :  8109  of 10000\n",
      "(TEST) Loss : 0.5621 Acc : 0.8109\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 26:\n",
      "(TRAIN) batch_number:  100 Loss : 0.7136 Acc : 0.79344\n",
      "(TRAIN) batch_number:  200 Loss : 0.7021 Acc : 0.79875\n",
      "(TRAIN) batch_number:  300 Loss : 0.5187 Acc : 0.79771\n",
      "(TRAIN) batch_number:  400 Loss : 0.5777 Acc : 0.79758\n",
      "(TRAIN) batch_number:  500 Loss : 0.4452 Acc : 0.79794\n",
      "(TRAIN) batch_number:  600 Loss : 0.6962 Acc : 0.79833\n",
      "(TRAIN) batch_number:  700 Loss : 0.7253 Acc : 0.7977\n",
      "(TEST) Correct_classified :  8114  of 10000\n",
      "(TEST) Loss : 0.558 Acc : 0.8114\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 27:\n",
      "(TRAIN) batch_number:  100 Loss : 0.5951 Acc : 0.80094\n",
      "(TRAIN) batch_number:  200 Loss : 0.5385 Acc : 0.79711\n",
      "(TRAIN) batch_number:  300 Loss : 0.5361 Acc : 0.79745\n",
      "(TRAIN) batch_number:  400 Loss : 0.7031 Acc : 0.79754\n",
      "(TRAIN) batch_number:  500 Loss : 0.5171 Acc : 0.79866\n",
      "(TRAIN) batch_number:  600 Loss : 0.7265 Acc : 0.79654\n",
      "(TRAIN) batch_number:  700 Loss : 0.8443 Acc : 0.79752\n",
      "(TEST) Correct_classified :  8079  of 10000\n",
      "(TEST) Loss : 0.5665 Acc : 0.8079\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 28:\n",
      "(TRAIN) batch_number:  100 Loss : 0.5658 Acc : 0.80219\n",
      "(TRAIN) batch_number:  200 Loss : 0.5702 Acc : 0.80133\n",
      "(TRAIN) batch_number:  300 Loss : 0.5238 Acc : 0.79854\n",
      "(TRAIN) batch_number:  400 Loss : 0.6653 Acc : 0.79789\n",
      "(TRAIN) batch_number:  500 Loss : 0.5404 Acc : 0.79825\n",
      "(TRAIN) batch_number:  600 Loss : 0.3885 Acc : 0.79852\n",
      "(TRAIN) batch_number:  700 Loss : 0.5503 Acc : 0.79844\n",
      "(TEST) Correct_classified :  8103  of 10000\n",
      "(TEST) Loss : 0.5605 Acc : 0.8103\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 29:\n",
      "(TRAIN) batch_number:  100 Loss : 0.2885 Acc : 0.795\n",
      "(TRAIN) batch_number:  200 Loss : 0.4084 Acc : 0.79875\n",
      "(TRAIN) batch_number:  300 Loss : 0.4767 Acc : 0.79693\n",
      "(TRAIN) batch_number:  400 Loss : 0.6441 Acc : 0.79703\n",
      "(TRAIN) batch_number:  500 Loss : 0.6023 Acc : 0.79769\n",
      "(TRAIN) batch_number:  600 Loss : 0.4159 Acc : 0.79747\n",
      "(TRAIN) batch_number:  700 Loss : 0.7074 Acc : 0.79719\n",
      "(TEST) Correct_classified :  8125  of 10000\n",
      "(TEST) Loss : 0.5584 Acc : 0.8125\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 30:\n",
      "(TRAIN) batch_number:  100 Loss : 0.6981 Acc : 0.79594\n",
      "(TRAIN) batch_number:  200 Loss : 0.7415 Acc : 0.79766\n",
      "(TRAIN) batch_number:  300 Loss : 0.6194 Acc : 0.79552\n",
      "(TRAIN) batch_number:  400 Loss : 0.7574 Acc : 0.7968\n",
      "(TRAIN) batch_number:  500 Loss : 0.5419 Acc : 0.79703\n",
      "(TRAIN) batch_number:  600 Loss : 0.421 Acc : 0.7969\n",
      "(TRAIN) batch_number:  700 Loss : 0.8267 Acc : 0.79703\n",
      "(TEST) Correct_classified :  8103  of 10000\n",
      "(TEST) Loss : 0.5633 Acc : 0.8103\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 31:\n",
      "(TRAIN) batch_number:  100 Loss :  0.5 Acc : 0.79766\n",
      "(TRAIN) batch_number:  200 Loss : 0.5122 Acc : 0.80117\n",
      "(TRAIN) batch_number:  300 Loss : 0.7222 Acc : 0.80135\n",
      "(TRAIN) batch_number:  400 Loss : 0.6448 Acc : 0.8007\n",
      "(TRAIN) batch_number:  500 Loss : 0.5429 Acc : 0.79944\n",
      "(TRAIN) batch_number:  600 Loss : 0.5207 Acc : 0.79826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TRAIN) batch_number:  700 Loss : 0.5795 Acc : 0.79725\n",
      "(TEST) Correct_classified :  8102  of 10000\n",
      "(TEST) Loss : 0.5593 Acc : 0.8102\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 32:\n",
      "(TRAIN) batch_number:  100 Loss : 0.4981 Acc : 0.80359\n",
      "(TRAIN) batch_number:  200 Loss : 0.6608 Acc : 0.79937\n",
      "(TRAIN) batch_number:  300 Loss : 0.7146 Acc : 0.79578\n",
      "(TRAIN) batch_number:  400 Loss : 0.5811 Acc : 0.79551\n",
      "(TRAIN) batch_number:  500 Loss : 0.655 Acc : 0.79534\n",
      "(TRAIN) batch_number:  600 Loss : 0.8092 Acc : 0.79529\n",
      "(TRAIN) batch_number:  700 Loss : 0.56 Acc : 0.79614\n",
      "(TEST) Correct_classified :  8116  of 10000\n",
      "(TEST) Loss : 0.5577 Acc : 0.8116\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 33:\n",
      "(TRAIN) batch_number:  100 Loss : 0.5517 Acc : 0.79984\n",
      "(TRAIN) batch_number:  200 Loss : 0.5443 Acc : 0.79609\n",
      "(TRAIN) batch_number:  300 Loss : 0.5607 Acc : 0.79943\n",
      "(TRAIN) batch_number:  400 Loss : 0.701 Acc : 0.80023\n",
      "(TRAIN) batch_number:  500 Loss : 0.7425 Acc : 0.80037\n",
      "(TRAIN) batch_number:  600 Loss : 0.4809 Acc : 0.79891\n",
      "(TRAIN) batch_number:  700 Loss : 0.8798 Acc : 0.79842\n",
      "(TEST) Correct_classified :  8109  of 10000\n",
      "(TEST) Loss : 0.5578 Acc : 0.8109\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 34:\n",
      "(TRAIN) batch_number:  100 Loss : 0.6016 Acc : 0.80797\n",
      "(TRAIN) batch_number:  200 Loss : 0.5753 Acc : 0.80266\n",
      "(TRAIN) batch_number:  300 Loss : 0.5047 Acc : 0.79828\n",
      "(TRAIN) batch_number:  400 Loss : 0.6531 Acc : 0.79883\n",
      "(TRAIN) batch_number:  500 Loss : 0.5323 Acc : 0.79969\n",
      "(TRAIN) batch_number:  600 Loss : 0.532 Acc : 0.79898\n",
      "(TRAIN) batch_number:  700 Loss : 0.655 Acc : 0.79837\n",
      "(TEST) Correct_classified :  8115  of 10000\n",
      "(TEST) Loss : 0.5611 Acc : 0.8115\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 35:\n",
      "(TRAIN) batch_number:  100 Loss : 0.7321 Acc : 0.79563\n",
      "(TRAIN) batch_number:  200 Loss : 0.4145 Acc : 0.79617\n",
      "(TRAIN) batch_number:  300 Loss : 0.6531 Acc : 0.79714\n",
      "(TRAIN) batch_number:  400 Loss : 0.6889 Acc : 0.795\n",
      "(TRAIN) batch_number:  500 Loss : 0.5212 Acc : 0.79591\n",
      "(TRAIN) batch_number:  600 Loss : 0.584 Acc : 0.79599\n",
      "(TRAIN) batch_number:  700 Loss : 0.4125 Acc : 0.79783\n",
      "(TEST) Correct_classified :  8114  of 10000\n",
      "(TEST) Loss : 0.5604 Acc : 0.8114\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 36:\n",
      "(TRAIN) batch_number:  100 Loss : 0.5397 Acc : 0.8025\n",
      "(TRAIN) batch_number:  200 Loss : 0.7868 Acc : 0.79773\n",
      "(TRAIN) batch_number:  300 Loss : 0.8745 Acc : 0.79542\n",
      "(TRAIN) batch_number:  400 Loss : 0.6115 Acc : 0.79746\n",
      "(TRAIN) batch_number:  500 Loss : 0.645 Acc : 0.79891\n",
      "(TRAIN) batch_number:  600 Loss : 0.5289 Acc : 0.79943\n",
      "(TRAIN) batch_number:  700 Loss : 1.185 Acc : 0.79908\n",
      "(TEST) Correct_classified :  8080  of 10000\n",
      "(TEST) Loss : 0.5661 Acc : 0.808\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 37:\n",
      "(TRAIN) batch_number:  100 Loss : 0.7037 Acc : 0.80047\n",
      "(TRAIN) batch_number:  200 Loss : 0.5825 Acc : 0.80219\n",
      "(TRAIN) batch_number:  300 Loss : 0.6131 Acc : 0.79896\n",
      "(TRAIN) batch_number:  400 Loss : 0.502 Acc : 0.7984\n",
      "(TRAIN) batch_number:  500 Loss : 0.5678 Acc : 0.79775\n",
      "(TRAIN) batch_number:  600 Loss : 0.5137 Acc : 0.79602\n",
      "(TRAIN) batch_number:  700 Loss : 0.639 Acc : 0.79634\n",
      "(TEST) Correct_classified :  8113  of 10000\n",
      "(TEST) Loss : 0.5596 Acc : 0.8113\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 38:\n",
      "(TRAIN) batch_number:  100 Loss : 0.5928 Acc :  0.8\n",
      "(TRAIN) batch_number:  200 Loss : 0.4397 Acc : 0.79766\n",
      "(TRAIN) batch_number:  300 Loss : 0.5864 Acc : 0.79583\n",
      "(TRAIN) batch_number:  400 Loss : 0.549 Acc : 0.79754\n",
      "(TRAIN) batch_number:  500 Loss : 0.7207 Acc : 0.79844\n",
      "(TRAIN) batch_number:  600 Loss : 0.7235 Acc : 0.79867\n",
      "(TRAIN) batch_number:  700 Loss : 0.5999 Acc : 0.79806\n",
      "(TEST) Correct_classified :  8101  of 10000\n",
      "(TEST) Loss : 0.5651 Acc : 0.8101\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 39:\n",
      "(TRAIN) batch_number:  100 Loss : 0.6494 Acc : 0.79812\n",
      "(TRAIN) batch_number:  200 Loss : 0.708 Acc : 0.795\n",
      "(TRAIN) batch_number:  300 Loss : 0.5772 Acc : 0.79542\n",
      "(TRAIN) batch_number:  400 Loss : 0.5199 Acc : 0.79441\n",
      "(TRAIN) batch_number:  500 Loss : 0.8275 Acc : 0.79472\n",
      "(TRAIN) batch_number:  600 Loss : 0.6136 Acc : 0.79635\n",
      "(TRAIN) batch_number:  700 Loss : 0.6038 Acc : 0.79815\n",
      "(TEST) Correct_classified :  8092  of 10000\n",
      "(TEST) Loss : 0.5603 Acc : 0.8092\n",
      "\n",
      " ************************************************************ \n",
      "\n",
      "\n",
      "Epoch 40:\n",
      "(TRAIN) batch_number:  100 Loss : 0.6563 Acc : 0.79641\n",
      "(TRAIN) batch_number:  200 Loss : 0.7469 Acc : 0.79555\n",
      "(TRAIN) batch_number:  300 Loss : 0.4995 Acc : 0.79693\n",
      "(TRAIN) batch_number:  400 Loss : 0.6271 Acc : 0.7984\n",
      "(TRAIN) batch_number:  500 Loss : 0.4573 Acc : 0.79759\n",
      "(TRAIN) batch_number:  600 Loss : 0.5132 Acc : 0.79698\n",
      "(TRAIN) batch_number:  700 Loss : 0.3721 Acc : 0.79694\n",
      "(TEST) Correct_classified :  8099  of 10000\n",
      "(TEST) Loss : 0.5601 Acc : 0.8099\n",
      "\n",
      " ************************************************************ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from run import run_model\n",
    "\n",
    "epochs = 40\n",
    "regularization = {'l1_factor':0,'l2_factor':0}\n",
    "\n",
    "model,train_trackers,test_trackers,incorrect_samples = run_model(model, train_loader, test_loader, epochs, device, **regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metric = 'LOSS'\n",
    "# Initialize a figure\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot values\n",
    "plain_plt, = plt.plot(test_trackers['test_losses'])\n",
    "\n",
    "\n",
    "# Set plot title\n",
    "plt.title(f'Validation {metric}')\n",
    "\n",
    "# Label axes\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(metric)\n",
    "\n",
    "# Set legend\n",
    "location = 'upper' if metric == 'Loss' else 'lower'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict() , 'C://Users//saina//Documents//EVA//S9//trained_quiz.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
